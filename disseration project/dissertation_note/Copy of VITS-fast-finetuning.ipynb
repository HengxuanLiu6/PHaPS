{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pn1xnFfdLK63gVXDwV4zCXfVeo8c-I-0","timestamp":1749674759670}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# 查看GPU配置\n","# Check GPU configuration\n","!nvidia-smi"],"metadata":{"id":"03vVx0mDtuwN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##(2023/07/23) 这个笔记本参考[HWcomss](https://github.com/HWcomss)的版本修改而成，现已可以正常工作。\n","##(23/07/2023) This notebook is a slightly modified version of [HWcomss](https://github.com/HWcomss)'s notebook, it's working fine now. Many thanks!\n"],"metadata":{"id":"fwJ-lNbOtp-9"}},{"cell_type":"code","source":["#@title STEP 1 复制代码库并安装运行环境\n","#@markdown #STEP 1 (6 min)\n","#@markdown ##复制代码库并安装运行环境\n","#@markdown ##Clone repository & Build environment\n","\n","!git clone https://github.com/Plachtaa/VITS-fast-fine-tuning.git\n","!python -m pip install --upgrade --force-reinstall regex\n","!python -m pip install --force-reinstall soundfile\n","!python -m pip install --force-reinstall gradio\n","!python -m pip install imageio==2.4.1\n","!python -m pip install --upgrade youtube-dl\n","!python -m pip install moviepy\n","%cd VITS-fast-fine-tuning\n","\n","!python -m pip install --no-build-isolation -r requirements.txt\n","!python -m pip install --upgrade numpy\n","!python -m pip install --upgrade --force-reinstall numba\n","!python -m pip install --upgrade Cython\n","\n","!python -m pip install --upgrade pyzmq\n","!python -m pip install pydantic==1.10.4\n","!python -m pip install ruamel.yaml\n","!python -m pip install git+https://github.com/openai/whisper.git\n","\n","# build monotonic align\n","%cd monotonic_align/\n","!mkdir monotonic_align\n","!python setup.py build_ext --inplace\n","%cd ..\n","!mkdir pretrained_models\n","# download data for fine-tuning\n","!wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/sampled_audio4ft_v2.zip\n","!unzip sampled_audio4ft_v2.zip\n","# create necessary directories\n","!mkdir video_data\n","!mkdir raw_audio\n","!mkdir denoised_audio\n","!mkdir custom_character_voice\n","!mkdir segmented_character_voice"],"metadata":{"id":"-XEdEXyTHVfD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title STEP 1.5 选择预训练模型\n","#@markdown ###STEP 1.5 选择预训练模型\n","#@markdown ###Choose pretrained model to start\n","#@markdown CJE为中日英三语模型，CJ为中日双语模型，C为纯中文模型\n","\n","#@markdown CJE for Chinese, Japanese & English model，CJ for Chinese & Japanese model\n","PRETRAINED_MODEL = \"CJE\" #@param [\"CJE\",\"CJ\",\"C\"]\n","if PRETRAINED_MODEL == \"CJ\":\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"CJE\":\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"C\":\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/D_0.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/G_0.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/config.json -O ./configs/finetune_speaker.json"],"metadata":{"id":"2tzsb5mR6-d9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title （可选）加载Google云端硬盘 / Mount Google drive\n","#@title (optional)\n","\n","#@markdown 加载Google云端硬盘（更快地上传数据集文件）\n","\n","#@markdown Mount Google drive for faster data upload\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"j1Q43oXND7Ih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STEP 3 自动处理所有上传的数据"],"metadata":{"id":"YQGC-JyAaD2D"}},{"cell_type":"code","source":["!cp /content/VITS-fast-fine-tuning/configs/modified_finetune_speaker.json \\\n","    /content/VITS-fast-fine-tuning/configs/finetune_speaker.json\n"],"metadata":{"id":"OGdE5imnbpW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find ./custom_character_voice -name \"*.wav\" | wc -l\n"],"metadata":{"id":"Cri1bM-5kT4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf /content/VITS-fast-fine-tuning\n","!cp -r \"/content/drive/MyDrive/dissertation project/dissertation_note/VITS-fast-fine-tuning\" /content/\n"],"metadata":{"id":"EPjzplatxni_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/VITS-fast-fine-tuning\n","\n"],"metadata":{"id":"BZqgFX6rxCe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf custom_character_voice/*\n"],"metadata":{"id":"NHLZmIg9lcvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf custom_character_voice/vits_ready_data/\n","!mv \"/content/drive/MyDrive/dissertation project/vits_ready_data\" custom_character_voice/\n","\n"],"metadata":{"id":"cpXE78rwlfYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls custom_character_voice"],"metadata":{"id":"xTJfWFIbdsob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv custom_character_voice/vits_ready_data/spk* custom_character_voice/\n","!rm -r custom_character_voice/vits_ready_data/\n"],"metadata":{"id":"LfU201ruNfTn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find custom_character_voice -name \"*.wav\" | wc -l\n"],"metadata":{"id":"vBu7BQn0mO9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","root_dir = \"custom_character_voice\"\n","output_file = \"short_character_anno.txt\"\n","\n","all_lines = []\n","speaker_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n","\n","for speaker in speaker_names:\n","    speaker_dir = os.path.join(root_dir, speaker)\n","    metadata_path = os.path.join(speaker_dir, \"metadata.csv\")\n","    if not os.path.exists(metadata_path):\n","        print(f\"！缺少 metadata.csv：{metadata_path}\")\n","        continue\n","\n","    with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                continue\n","            try:\n","                filename, text = line.split(\"|\")\n","                audio_path = os.path.join(speaker_dir, filename)\n","                formatted = f\"{audio_path}|{speaker}|[EN]{text}[EN]\\n\"\n","                all_lines.append(formatted)\n","            except ValueError:\n","                print(f\"！跳过格式错误的行：{line}\")\n","\n","with open(output_file, \"w\", encoding=\"utf-8\") as f:\n","    f.writelines(all_lines)\n","\n","print(f\"已写入 {len(all_lines)} 条标注到 {output_file}\")\n"],"metadata":{"id":"V6HnCdG2cMnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchaudio\n","waveform, sr = torchaudio.load(\"custom_character_voice/spk1/0000.wav\")\n","print(\"当前采样率:\", sr)\n"],"metadata":{"id":"C5RtVdMglDFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python scripts/resample.py"],"metadata":{"id":"rcpjQ6qGhMmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown 运行该单元格会对所有上传的数据进行自动去背景音&标注。\n","#@markdown 由于需要调用Whisper和Demucs，运行时间可能较长。\n","\n","#@markdown Running this codeblock will perform automatic vocal seperation & annotation.\n","#@markdown Since this step uses Whisper & Demucs, it may take a while to complete.\n","# 将所有视频（无论是上传的还是下载的，且必须是.mp4格式）抽取音频\n","# %run scripts/video2audio.py\n","# # 将所有音频（无论是上传的还是从视频抽取的，必须是.wav格式）去噪\n","# !python scripts/denoise_audio.py\n","# # 分割并标注长音频\n","# !python scripts/long_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large-v2\n","# 标注短音频\n","# !python scripts/short_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large-v2\n","!python scripts/short_audio_transcribe.py --languages en --whisper_size large-v2\n","\n","\n","# 底模采样率可能与辅助数据不同，需要重采样\n","!python scripts/resample.py"],"metadata":{"id":"aJOO7VsPQf3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import torchaudio\n","from tqdm import tqdm\n","\n","def resample_all_custom_voice():\n","    # 读取目标采样率（如 22050）\n","    with open(\"./configs/finetune_speaker.json\", 'r', encoding='utf-8') as f:\n","        hps = json.load(f)\n","    target_sr = hps['data']['sampling_rate']\n","\n","    root_dir = \"./custom_character_voice\"\n","    speakers = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n","\n","    for speaker in speakers:\n","        speaker_dir = os.path.join(root_dir, speaker)\n","        wav_files = [f for f in os.listdir(speaker_dir) if f.endswith(\".wav\")]\n","\n","        print(f\"\\n📢 正在处理 speaker：{speaker}，共 {len(wav_files)} 个音频文件\")\n","        for wavfile in tqdm(wav_files):\n","            wav_path = os.path.join(speaker_dir, wavfile)\n","            try:\n","                wav, sr = torchaudio.load(wav_path)\n","                if sr != target_sr:\n","                    wav = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)(wav)\n","                    torchaudio.save(wav_path, wav, target_sr)\n","            except Exception as e:\n","                print(f\"！处理失败: {wav_path}，原因: {e}\")\n","\n","    print(\"Yes！ 所有音频重采样完成！\")\n","\n","if __name__ == \"__main__\":\n","    resample_all_custom_voice()\n"],"metadata":{"id":"fNCfyGWClzlK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#！！！训练质量相关：实验发现目前使用CJ模型+勾选ADD_AUXILIARY，对于中/日均能训练出最好的效果，第一次训练建议默认使用该组合！！！"],"metadata":{"id":"WY12Ien-BUE7"}},{"cell_type":"code","source":["!pip install -U numpy unidecode pyopenjtalk jamo ko-pron cn2an pypinyin jieba indic-transliteration librosa scipy tqdm inflect num2words eng-to-ipa opencc-python-reimplemented beautifulsoup4 requests phonemizer\n"],"metadata":{"id":"an0U0qywuQ4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install num-thai\n"],"metadata":{"id":"EbiQTQu11d6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ##STEP 3.5\n","#@markdown 运行该单元格会生成划分好训练/测试集的最终标注，以及配置文件\n","\n","#@markdown Running this block will generate final annotations for training & validation, as well as config file.\n","\n","#@markdown 选择是否加入辅助训练数据：/ Choose whether to add auxiliary data:\n","ADD_AUXILIARY = False #@param {type:\"boolean\"}\n","#@markdown 辅助训练数据是从预训练的大数据集抽样得到的，作用在于防止模型在标注不准确的数据上形成错误映射。\n","\n","#@markdown Auxiliary data is to prevent overfitting when the audio samples are small or with low quality.\n","\n","#@markdown 以下情况请勾选：\n","\n","#@markdown 总样本少于100条/样本质量一般或较差/样本来自爬取的视频\n","\n","#@markdown 以下情况可以不勾选：\n","\n","#@markdown 总样本量很大/样本质量很高/希望加速训练/只有二次元角色\n","\n","# assert(not (ADD_AUXILIARY and PRETRAINED_MODEL != \"CJE\")), \"add auxiliary data is available only available for CJE model!\"\n","if ADD_AUXILIARY:\n","  %run preprocess_v2.py --add_auxiliary_data True --languages \"{PRETRAINED_MODEL}\"\n","else:\n","  %run preprocess_v2.py --languages \"{PRETRAINED_MODEL}\""],"metadata":{"id":"G_IM97N2e6fk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STEP 4 开始训练"],"metadata":{"id":"VA4hV2G_fyKz"}},{"cell_type":"code","source":["!mkdir -p /content/VITS-fast-fine-tuning/pretrained_models\n"],"metadata":{"id":"9eQLmNB-45ac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 删除损坏文件\n","!rm -f /content/VITS-fast-fine-tuning/pretrained_models/G_0.pth\n","\n","# 重新下载 CJE 模型\n","!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth \\\n","     -O /content/VITS-fast-fine-tuning/pretrained_models/G_0.pth\n"],"metadata":{"id":"SWzysMMm6bZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -lh /content/VITS-fast-fine-tuning/pretrained_models/G_0.pth\n"],"metadata":{"id":"ZOV2qAZ861ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json \\\n","     -O configs/finetune_speaker.json\n"],"metadata":{"id":"Drkqnc027a4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth \\\n","     -O ./pretrained_models/D_0.pth\n"],"metadata":{"id":"ykqtDRmb-d-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf /content/VITS-fast-fine-tuning/__pycache__\n","!find /content/VITS-fast-fine-tuning -type d -name \"__pycache__\" -exec rm -rf {} +\n"],"metadata":{"id":"R8elfrZvDcbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown #STEP 4 (>=20 min)\n","#@markdown 开始微调模型。\n","#@markdown 训练时长取决于你录入/上传的音频总数。\n","\n","#@markdown 根据声线和样本质量的不同，所需的训练epochs数也不同。\n","\n","#@markdown 你也可以在Tensorboard中预览合成效果，若效果满意可提前停止。\n","\n","#@markdown Model fine-tuning\n","#@markdown Total time cost depends on the number of voices you recorded/uploaded.\n","\n","#@markdown Best epoch number varies depending on different uploaded voices / sample quality.\n","\n","#@markdown You can also preview synthezied audio in Tensorboard, it's OK to shut down training manually if you find the quality is satisfying.\n","import os\n","os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n","\n","if os.path.exists(\"/content/drive/MyDrive/\"):\n","  !python scripts/rearrange_speaker.py\n","  !cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n","  !cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json\n","\n","%reload_ext tensorboard\n","%tensorboard --logdir \"./OUTPUT_MODEL\"\n","Maximum_epochs = \"200\" #@param {type:\"string\"}\n","#@markdown 继续之前的模型训练/Continue training from previous checkpoint\n","CONTINUE = True #@param {type:\"boolean\"}\n","if CONTINUE:\n","  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed False --cont True\n","else:\n","  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed True"],"metadata":{"id":"4gmpTNtcW2Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pydantic==1.10.13 --force-reinstall\n","!pip install gradio==3.41.2  # 可选，用于确保配套版本\n"],"metadata":{"id":"mV-DvZmtvf-p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# STEP 5 下载模型\n","## 本地部署方法请见[README](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_ZH.md)"],"metadata":{"id":"MXYxSdt-m3YK"}},{"cell_type":"code","source":["#@markdown ### 下载选项1：运行该单元格，浏览器会自动下载模型和配置文件\n","#@markdown ### Download option 1: Running this codeblock will download model & config files by your browser.\n","!python scripts/rearrange_speaker.py\n","%run scripts/download_model.py"],"metadata":{"id":"QcJQm6_ImD7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### 下载选项2：运行该单元格会将模型和配置文件保存到Google云端硬盘\n","#@markdown ### Download option 2: Running this codeblock will save the mode & config files to your Google drive.\n","!python scripts/rearrange_speaker.py\n","!cp ./G_latest.pth ../drive/MyDrive/G_latest.pth\n","!cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n","!cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json"],"metadata":{"id":"k13JBTommkTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### 运行该单元格会清空所有已上传的样本，需要时可使用\n","#@markdown ### Running this codeblock will delete all voice samples you have uploaded. Use it if you need.\n","!rm -rf ./custom_character_voice/*\n","!rm -rf ./video_data/*\n","!rm -rf ./raw_audio/*\n","!rm -rf ./denoised_audio/*\n","!rm -rf ./segmented_character_voice/*\n","!rm -rf long_character_anno.txt\n","!rm -rf short_character_anno.txt"],"metadata":{"id":"hU8LmJlUcF1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### 运行该单元格会将切片和标注复制到谷歌云端硬盘根目录下名为`voice_data`的文件夹下以用作其它用途\n","#@markdown ### Running this codeblock will copy all processed voices & annotations to a folder named `voice_data` under the root of Google Drive for other purpose of usage\n","!mkdir ../drive/MyDrive/voice_data/\n","!cp -rf ./custom_character_voice/ ../drive/MyDrive/voice_data/custom_character_voice/\n","!cp -rf ./segmented_character_voice/ ../drive/MyDrive/voice_data/segmented_character_voice/\n","!cp long_character_anno.txt ../drive/MyDrive/voice_data/long_character_anno.txt\n","!cp short_character_anno.txt ../drive/MyDrive/voice_data/short_character_anno.txt"],"metadata":{"id":"ZHK6qw4wRF8T"},"execution_count":null,"outputs":[]}]}