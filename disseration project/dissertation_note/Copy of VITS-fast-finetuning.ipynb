{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1pn1xnFfdLK63gVXDwV4zCXfVeo8c-I-0","timestamp":1749674759670}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# æŸ¥çœ‹GPUé…ç½®\n","# Check GPU configuration\n","!nvidia-smi"],"metadata":{"id":"03vVx0mDtuwN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##(2023/07/23) è¿™ä¸ªç¬”è®°æœ¬å‚è€ƒ[HWcomss](https://github.com/HWcomss)çš„ç‰ˆæœ¬ä¿®æ”¹è€Œæˆï¼Œç°å·²å¯ä»¥æ­£å¸¸å·¥ä½œã€‚\n","##(23/07/2023) This notebook is a slightly modified version of [HWcomss](https://github.com/HWcomss)'s notebook, it's working fine now. Many thanks!\n"],"metadata":{"id":"fwJ-lNbOtp-9"}},{"cell_type":"code","source":["#@title STEP 1 å¤åˆ¶ä»£ç åº“å¹¶å®‰è£…è¿è¡Œç¯å¢ƒ\n","#@markdown #STEP 1 (6 min)\n","#@markdown ##å¤åˆ¶ä»£ç åº“å¹¶å®‰è£…è¿è¡Œç¯å¢ƒ\n","#@markdown ##Clone repository & Build environment\n","\n","!git clone https://github.com/Plachtaa/VITS-fast-fine-tuning.git\n","!python -m pip install --upgrade --force-reinstall regex\n","!python -m pip install --force-reinstall soundfile\n","!python -m pip install --force-reinstall gradio\n","!python -m pip install imageio==2.4.1\n","!python -m pip install --upgrade youtube-dl\n","!python -m pip install moviepy\n","%cd VITS-fast-fine-tuning\n","\n","!python -m pip install --no-build-isolation -r requirements.txt\n","!python -m pip install --upgrade numpy\n","!python -m pip install --upgrade --force-reinstall numba\n","!python -m pip install --upgrade Cython\n","\n","!python -m pip install --upgrade pyzmq\n","!python -m pip install pydantic==1.10.4\n","!python -m pip install ruamel.yaml\n","!python -m pip install git+https://github.com/openai/whisper.git\n","\n","# build monotonic align\n","%cd monotonic_align/\n","!mkdir monotonic_align\n","!python setup.py build_ext --inplace\n","%cd ..\n","!mkdir pretrained_models\n","# download data for fine-tuning\n","!wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/sampled_audio4ft_v2.zip\n","!unzip sampled_audio4ft_v2.zip\n","# create necessary directories\n","!mkdir video_data\n","!mkdir raw_audio\n","!mkdir denoised_audio\n","!mkdir custom_character_voice\n","!mkdir segmented_character_voice"],"metadata":{"id":"-XEdEXyTHVfD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title STEP 1.5 é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹\n","#@markdown ###STEP 1.5 é€‰æ‹©é¢„è®­ç»ƒæ¨¡å‹\n","#@markdown ###Choose pretrained model to start\n","#@markdown CJEä¸ºä¸­æ—¥è‹±ä¸‰è¯­æ¨¡å‹ï¼ŒCJä¸ºä¸­æ—¥åŒè¯­æ¨¡å‹ï¼ŒCä¸ºçº¯ä¸­æ–‡æ¨¡å‹\n","\n","#@markdown CJE for Chinese, Japanese & English modelï¼ŒCJ for Chinese & Japanese model\n","PRETRAINED_MODEL = \"CJE\" #@param [\"CJE\",\"CJ\",\"C\"]\n","if PRETRAINED_MODEL == \"CJ\":\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"CJE\":\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"C\":\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/D_0.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/G_0.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/config.json -O ./configs/finetune_speaker.json"],"metadata":{"id":"2tzsb5mR6-d9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title ï¼ˆå¯é€‰ï¼‰åŠ è½½Googleäº‘ç«¯ç¡¬ç›˜ / Mount Google drive\n","#@title (optional)\n","\n","#@markdown åŠ è½½Googleäº‘ç«¯ç¡¬ç›˜ï¼ˆæ›´å¿«åœ°ä¸Šä¼ æ•°æ®é›†æ–‡ä»¶ï¼‰\n","\n","#@markdown Mount Google drive for faster data upload\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"j1Q43oXND7Ih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STEP 3 è‡ªåŠ¨å¤„ç†æ‰€æœ‰ä¸Šä¼ çš„æ•°æ®"],"metadata":{"id":"YQGC-JyAaD2D"}},{"cell_type":"code","source":["!cp /content/VITS-fast-fine-tuning/configs/modified_finetune_speaker.json \\\n","    /content/VITS-fast-fine-tuning/configs/finetune_speaker.json\n"],"metadata":{"id":"OGdE5imnbpW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find ./custom_character_voice -name \"*.wav\" | wc -l\n"],"metadata":{"id":"Cri1bM-5kT4c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf /content/VITS-fast-fine-tuning\n","!cp -r \"/content/drive/MyDrive/dissertation project/dissertation_note/VITS-fast-fine-tuning\" /content/\n"],"metadata":{"id":"EPjzplatxni_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/VITS-fast-fine-tuning\n","\n"],"metadata":{"id":"BZqgFX6rxCe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf custom_character_voice/*\n"],"metadata":{"id":"NHLZmIg9lcvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf custom_character_voice/vits_ready_data/\n","!mv \"/content/drive/MyDrive/dissertation project/vits_ready_data\" custom_character_voice/\n","\n"],"metadata":{"id":"cpXE78rwlfYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls custom_character_voice"],"metadata":{"id":"xTJfWFIbdsob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv custom_character_voice/vits_ready_data/spk* custom_character_voice/\n","!rm -r custom_character_voice/vits_ready_data/\n"],"metadata":{"id":"LfU201ruNfTn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find custom_character_voice -name \"*.wav\" | wc -l\n"],"metadata":{"id":"vBu7BQn0mO9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","root_dir = \"custom_character_voice\"\n","output_file = \"short_character_anno.txt\"\n","\n","all_lines = []\n","speaker_names = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n","\n","for speaker in speaker_names:\n","    speaker_dir = os.path.join(root_dir, speaker)\n","    metadata_path = os.path.join(speaker_dir, \"metadata.csv\")\n","    if not os.path.exists(metadata_path):\n","        print(f\"ï¼ç¼ºå°‘ metadata.csvï¼š{metadata_path}\")\n","        continue\n","\n","    with open(metadata_path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                continue\n","            try:\n","                filename, text = line.split(\"|\")\n","                audio_path = os.path.join(speaker_dir, filename)\n","                formatted = f\"{audio_path}|{speaker}|[EN]{text}[EN]\\n\"\n","                all_lines.append(formatted)\n","            except ValueError:\n","                print(f\"ï¼è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œï¼š{line}\")\n","\n","with open(output_file, \"w\", encoding=\"utf-8\") as f:\n","    f.writelines(all_lines)\n","\n","print(f\"å·²å†™å…¥ {len(all_lines)} æ¡æ ‡æ³¨åˆ° {output_file}\")\n"],"metadata":{"id":"V6HnCdG2cMnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchaudio\n","waveform, sr = torchaudio.load(\"custom_character_voice/spk1/0000.wav\")\n","print(\"å½“å‰é‡‡æ ·ç‡:\", sr)\n"],"metadata":{"id":"C5RtVdMglDFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python scripts/resample.py"],"metadata":{"id":"rcpjQ6qGhMmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown è¿è¡Œè¯¥å•å…ƒæ ¼ä¼šå¯¹æ‰€æœ‰ä¸Šä¼ çš„æ•°æ®è¿›è¡Œè‡ªåŠ¨å»èƒŒæ™¯éŸ³&æ ‡æ³¨ã€‚\n","#@markdown ç”±äºéœ€è¦è°ƒç”¨Whisperå’ŒDemucsï¼Œè¿è¡Œæ—¶é—´å¯èƒ½è¾ƒé•¿ã€‚\n","\n","#@markdown Running this codeblock will perform automatic vocal seperation & annotation.\n","#@markdown Since this step uses Whisper & Demucs, it may take a while to complete.\n","# å°†æ‰€æœ‰è§†é¢‘ï¼ˆæ— è®ºæ˜¯ä¸Šä¼ çš„è¿˜æ˜¯ä¸‹è½½çš„ï¼Œä¸”å¿…é¡»æ˜¯.mp4æ ¼å¼ï¼‰æŠ½å–éŸ³é¢‘\n","# %run scripts/video2audio.py\n","# # å°†æ‰€æœ‰éŸ³é¢‘ï¼ˆæ— è®ºæ˜¯ä¸Šä¼ çš„è¿˜æ˜¯ä»è§†é¢‘æŠ½å–çš„ï¼Œå¿…é¡»æ˜¯.wavæ ¼å¼ï¼‰å»å™ª\n","# !python scripts/denoise_audio.py\n","# # åˆ†å‰²å¹¶æ ‡æ³¨é•¿éŸ³é¢‘\n","# !python scripts/long_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large-v2\n","# æ ‡æ³¨çŸ­éŸ³é¢‘\n","# !python scripts/short_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large-v2\n","!python scripts/short_audio_transcribe.py --languages en --whisper_size large-v2\n","\n","\n","# åº•æ¨¡é‡‡æ ·ç‡å¯èƒ½ä¸è¾…åŠ©æ•°æ®ä¸åŒï¼Œéœ€è¦é‡é‡‡æ ·\n","!python scripts/resample.py"],"metadata":{"id":"aJOO7VsPQf3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","import torchaudio\n","from tqdm import tqdm\n","\n","def resample_all_custom_voice():\n","    # è¯»å–ç›®æ ‡é‡‡æ ·ç‡ï¼ˆå¦‚ 22050ï¼‰\n","    with open(\"./configs/finetune_speaker.json\", 'r', encoding='utf-8') as f:\n","        hps = json.load(f)\n","    target_sr = hps['data']['sampling_rate']\n","\n","    root_dir = \"./custom_character_voice\"\n","    speakers = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n","\n","    for speaker in speakers:\n","        speaker_dir = os.path.join(root_dir, speaker)\n","        wav_files = [f for f in os.listdir(speaker_dir) if f.endswith(\".wav\")]\n","\n","        print(f\"\\nğŸ“¢ æ­£åœ¨å¤„ç† speakerï¼š{speaker}ï¼Œå…± {len(wav_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶\")\n","        for wavfile in tqdm(wav_files):\n","            wav_path = os.path.join(speaker_dir, wavfile)\n","            try:\n","                wav, sr = torchaudio.load(wav_path)\n","                if sr != target_sr:\n","                    wav = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)(wav)\n","                    torchaudio.save(wav_path, wav, target_sr)\n","            except Exception as e:\n","                print(f\"ï¼å¤„ç†å¤±è´¥: {wav_path}ï¼ŒåŸå› : {e}\")\n","\n","    print(\"Yesï¼ æ‰€æœ‰éŸ³é¢‘é‡é‡‡æ ·å®Œæˆï¼\")\n","\n","if __name__ == \"__main__\":\n","    resample_all_custom_voice()\n"],"metadata":{"id":"fNCfyGWClzlK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ï¼ï¼ï¼è®­ç»ƒè´¨é‡ç›¸å…³ï¼šå®éªŒå‘ç°ç›®å‰ä½¿ç”¨CJæ¨¡å‹+å‹¾é€‰ADD_AUXILIARYï¼Œå¯¹äºä¸­/æ—¥å‡èƒ½è®­ç»ƒå‡ºæœ€å¥½çš„æ•ˆæœï¼Œç¬¬ä¸€æ¬¡è®­ç»ƒå»ºè®®é»˜è®¤ä½¿ç”¨è¯¥ç»„åˆï¼ï¼ï¼"],"metadata":{"id":"WY12Ien-BUE7"}},{"cell_type":"code","source":["!pip install -U numpy unidecode pyopenjtalk jamo ko-pron cn2an pypinyin jieba indic-transliteration librosa scipy tqdm inflect num2words eng-to-ipa opencc-python-reimplemented beautifulsoup4 requests phonemizer\n"],"metadata":{"id":"an0U0qywuQ4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install num-thai\n"],"metadata":{"id":"EbiQTQu11d6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ##STEP 3.5\n","#@markdown è¿è¡Œè¯¥å•å…ƒæ ¼ä¼šç”Ÿæˆåˆ’åˆ†å¥½è®­ç»ƒ/æµ‹è¯•é›†çš„æœ€ç»ˆæ ‡æ³¨ï¼Œä»¥åŠé…ç½®æ–‡ä»¶\n","\n","#@markdown Running this block will generate final annotations for training & validation, as well as config file.\n","\n","#@markdown é€‰æ‹©æ˜¯å¦åŠ å…¥è¾…åŠ©è®­ç»ƒæ•°æ®ï¼š/ Choose whether to add auxiliary data:\n","ADD_AUXILIARY = False #@param {type:\"boolean\"}\n","#@markdown è¾…åŠ©è®­ç»ƒæ•°æ®æ˜¯ä»é¢„è®­ç»ƒçš„å¤§æ•°æ®é›†æŠ½æ ·å¾—åˆ°çš„ï¼Œä½œç”¨åœ¨äºé˜²æ­¢æ¨¡å‹åœ¨æ ‡æ³¨ä¸å‡†ç¡®çš„æ•°æ®ä¸Šå½¢æˆé”™è¯¯æ˜ å°„ã€‚\n","\n","#@markdown Auxiliary data is to prevent overfitting when the audio samples are small or with low quality.\n","\n","#@markdown ä»¥ä¸‹æƒ…å†µè¯·å‹¾é€‰ï¼š\n","\n","#@markdown æ€»æ ·æœ¬å°‘äº100æ¡/æ ·æœ¬è´¨é‡ä¸€èˆ¬æˆ–è¾ƒå·®/æ ·æœ¬æ¥è‡ªçˆ¬å–çš„è§†é¢‘\n","\n","#@markdown ä»¥ä¸‹æƒ…å†µå¯ä»¥ä¸å‹¾é€‰ï¼š\n","\n","#@markdown æ€»æ ·æœ¬é‡å¾ˆå¤§/æ ·æœ¬è´¨é‡å¾ˆé«˜/å¸Œæœ›åŠ é€Ÿè®­ç»ƒ/åªæœ‰äºŒæ¬¡å…ƒè§’è‰²\n","\n","# assert(not (ADD_AUXILIARY and PRETRAINED_MODEL != \"CJE\")), \"add auxiliary data is available only available for CJE model!\"\n","if ADD_AUXILIARY:\n","  %run preprocess_v2.py --add_auxiliary_data True --languages \"{PRETRAINED_MODEL}\"\n","else:\n","  %run preprocess_v2.py --languages \"{PRETRAINED_MODEL}\""],"metadata":{"id":"G_IM97N2e6fk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## STEP 4 å¼€å§‹è®­ç»ƒ"],"metadata":{"id":"VA4hV2G_fyKz"}},{"cell_type":"code","source":["!mkdir -p /content/VITS-fast-fine-tuning/pretrained_models\n"],"metadata":{"id":"9eQLmNB-45ac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# åˆ é™¤æŸåæ–‡ä»¶\n","!rm -f /content/VITS-fast-fine-tuning/pretrained_models/G_0.pth\n","\n","# é‡æ–°ä¸‹è½½ CJE æ¨¡å‹\n","!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth \\\n","     -O /content/VITS-fast-fine-tuning/pretrained_models/G_0.pth\n"],"metadata":{"id":"SWzysMMm6bZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -lh /content/VITS-fast-fine-tuning/pretrained_models/G_0.pth\n"],"metadata":{"id":"ZOV2qAZ861ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json \\\n","     -O configs/finetune_speaker.json\n"],"metadata":{"id":"Drkqnc027a4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth \\\n","     -O ./pretrained_models/D_0.pth\n"],"metadata":{"id":"ykqtDRmb-d-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf /content/VITS-fast-fine-tuning/__pycache__\n","!find /content/VITS-fast-fine-tuning -type d -name \"__pycache__\" -exec rm -rf {} +\n"],"metadata":{"id":"R8elfrZvDcbb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown #STEP 4 (>=20 min)\n","#@markdown å¼€å§‹å¾®è°ƒæ¨¡å‹ã€‚\n","#@markdown è®­ç»ƒæ—¶é•¿å–å†³äºä½ å½•å…¥/ä¸Šä¼ çš„éŸ³é¢‘æ€»æ•°ã€‚\n","\n","#@markdown æ ¹æ®å£°çº¿å’Œæ ·æœ¬è´¨é‡çš„ä¸åŒï¼Œæ‰€éœ€çš„è®­ç»ƒepochsæ•°ä¹Ÿä¸åŒã€‚\n","\n","#@markdown ä½ ä¹Ÿå¯ä»¥åœ¨Tensorboardä¸­é¢„è§ˆåˆæˆæ•ˆæœï¼Œè‹¥æ•ˆæœæ»¡æ„å¯æå‰åœæ­¢ã€‚\n","\n","#@markdown Model fine-tuning\n","#@markdown Total time cost depends on the number of voices you recorded/uploaded.\n","\n","#@markdown Best epoch number varies depending on different uploaded voices / sample quality.\n","\n","#@markdown You can also preview synthezied audio in Tensorboard, it's OK to shut down training manually if you find the quality is satisfying.\n","import os\n","os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n","\n","if os.path.exists(\"/content/drive/MyDrive/\"):\n","  !python scripts/rearrange_speaker.py\n","  !cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n","  !cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json\n","\n","%reload_ext tensorboard\n","%tensorboard --logdir \"./OUTPUT_MODEL\"\n","Maximum_epochs = \"200\" #@param {type:\"string\"}\n","#@markdown ç»§ç»­ä¹‹å‰çš„æ¨¡å‹è®­ç»ƒ/Continue training from previous checkpoint\n","CONTINUE = True #@param {type:\"boolean\"}\n","if CONTINUE:\n","  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed False --cont True\n","else:\n","  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed True"],"metadata":{"id":"4gmpTNtcW2Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pydantic==1.10.13 --force-reinstall\n","!pip install gradio==3.41.2  # å¯é€‰ï¼Œç”¨äºç¡®ä¿é…å¥—ç‰ˆæœ¬\n"],"metadata":{"id":"mV-DvZmtvf-p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# STEP 5 ä¸‹è½½æ¨¡å‹\n","## æœ¬åœ°éƒ¨ç½²æ–¹æ³•è¯·è§[README](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_ZH.md)"],"metadata":{"id":"MXYxSdt-m3YK"}},{"cell_type":"code","source":["#@markdown ### ä¸‹è½½é€‰é¡¹1ï¼šè¿è¡Œè¯¥å•å…ƒæ ¼ï¼Œæµè§ˆå™¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹å’Œé…ç½®æ–‡ä»¶\n","#@markdown ### Download option 1: Running this codeblock will download model & config files by your browser.\n","!python scripts/rearrange_speaker.py\n","%run scripts/download_model.py"],"metadata":{"id":"QcJQm6_ImD7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### ä¸‹è½½é€‰é¡¹2ï¼šè¿è¡Œè¯¥å•å…ƒæ ¼ä¼šå°†æ¨¡å‹å’Œé…ç½®æ–‡ä»¶ä¿å­˜åˆ°Googleäº‘ç«¯ç¡¬ç›˜\n","#@markdown ### Download option 2: Running this codeblock will save the mode & config files to your Google drive.\n","!python scripts/rearrange_speaker.py\n","!cp ./G_latest.pth ../drive/MyDrive/G_latest.pth\n","!cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n","!cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json"],"metadata":{"id":"k13JBTommkTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### è¿è¡Œè¯¥å•å…ƒæ ¼ä¼šæ¸…ç©ºæ‰€æœ‰å·²ä¸Šä¼ çš„æ ·æœ¬ï¼Œéœ€è¦æ—¶å¯ä½¿ç”¨\n","#@markdown ### Running this codeblock will delete all voice samples you have uploaded. Use it if you need.\n","!rm -rf ./custom_character_voice/*\n","!rm -rf ./video_data/*\n","!rm -rf ./raw_audio/*\n","!rm -rf ./denoised_audio/*\n","!rm -rf ./segmented_character_voice/*\n","!rm -rf long_character_anno.txt\n","!rm -rf short_character_anno.txt"],"metadata":{"id":"hU8LmJlUcF1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### è¿è¡Œè¯¥å•å…ƒæ ¼ä¼šå°†åˆ‡ç‰‡å’Œæ ‡æ³¨å¤åˆ¶åˆ°è°·æ­Œäº‘ç«¯ç¡¬ç›˜æ ¹ç›®å½•ä¸‹åä¸º`voice_data`çš„æ–‡ä»¶å¤¹ä¸‹ä»¥ç”¨ä½œå…¶å®ƒç”¨é€”\n","#@markdown ### Running this codeblock will copy all processed voices & annotations to a folder named `voice_data` under the root of Google Drive for other purpose of usage\n","!mkdir ../drive/MyDrive/voice_data/\n","!cp -rf ./custom_character_voice/ ../drive/MyDrive/voice_data/custom_character_voice/\n","!cp -rf ./segmented_character_voice/ ../drive/MyDrive/voice_data/segmented_character_voice/\n","!cp long_character_anno.txt ../drive/MyDrive/voice_data/long_character_anno.txt\n","!cp short_character_anno.txt ../drive/MyDrive/voice_data/short_character_anno.txt"],"metadata":{"id":"ZHK6qw4wRF8T"},"execution_count":null,"outputs":[]}]}