# PHaPS

This project investigates whether selecting speech audio data based on linguistic features
can improve the performance of state-of-the-art (SOTA) automatic speech recognition
(ASR) systems, in the context of mitigating the performance gap between Mandarinaccented English (MAE) and American English (AE) observed in Whisper. To this end, we
propose a phoneme-aware data selection method, PHaPS, which focuses on phonemelevel characteristics of accented English. We applied PHaPS to fine-tune the Whisper
model and compared its performance with models fine-tuned using traditional data
augmentation strategies. Our results show that PHaPS achieves the highest data efficiency,
improving data usage by 67% compared to the baseline. This highlights the importance
of data quality over quantity and the value of targeting phoneme-level features. We also
experimented with using synthesized data generated by Text-to-Speech (TTS) systems to
support low-resource accented ASR. However, the results suggest that current TTS systems
are not yet effective for this purpose.

<!-- # PHaPS: Fine-tuning ASR Models with Synthesized and Optimized Data

This repository contains all the code, data handling scripts, and evaluation notebooks used in the dissertation project focused on improving ASR models through data optimization and synthesized speech. -->

---

## WER Evaluation

The notebook [`Chinese_model_text.ipynb`](dissertation_note/Chinese_model_text.ipynb) is used to:

- Evaluate the **Word Error Rate (WER)** of each ASR model.
- Perform **phoneme-level error analysis** to understand model behavior more precisely.

---

## Data Optimization

We apply three data optimization techniques in this project:

- [`sp.py`](dissertation_note/sp.py): Speed perturbation.  
- [`pp.py`](dissertation_note/pp.py): Pitch perturbation.  
- [`flatten_dataset.py`](dissertation_note/flatten_dataset.py): Merges different speed or pitch variants into a single dataset.  
- [`phoneme_selector.py`](dissertation_note/phoneme_selector.py): Selects utterances for PHaPS based on phoneme distribution.

All model fine-tuning is executed via [`main.py`](dissertation_note/main.py).

---

## Synthesized Speech Pipeline

- The fine-tuning of **VITS-Fast-Fine-Tuning** is performed using [`Copy of VITS-fast-finetuning.ipynb`](dissertation_note/Copy%20of%20VITS-fast-finetuning.ipynb).
- The script [`make_parquet.py`](dissertation_note/synthesis_datasets/make_parquet.py) generates a dataset compatible with the AESRC2020 format using synthesized speech.
- MOS prediction and analysis are handled in [`MOS.ipynb`](dissertation_note/MOS.ipynb).

---

## Colab Environment

All experiments were conducted in **Google Colab** for flexibility and ease of access.

ðŸ”— [Project Drive Folder](https://drive.google.com/drive/folders/19Yttho4DIuYt6OcMJ--ISQpmjGo-mVnm?usp=drive_link) â€“ includes full code, data, and results.

<!-- ---

Feel free to explore the code, run experiments, and adapt it to your own research in accented ASR and data efficiency.
 -->
